# DFJSP-T å±‚çº§å¼ºåŒ–å­¦ä¹ é¡¹ç›® - å¿«é€Ÿå¼€å§‹

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†**å±‚çº§åå¥½å¼•å¯¼çš„å¸•ç´¯æ‰˜æœç´¢æ¡†æ¶**ç”¨äºè§£å†³å¤šç›®æ ‡DFJSP-Té—®é¢˜ï¼ˆå¸¦è¿è¾“æœºå™¨äººçš„æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦ï¼‰ã€‚

**æ ¸å¿ƒåˆ›æ–°**ï¼šMethod 3 æ¶æ„ - ç­–ç•¥å…ƒæ§åˆ¶å™¨ + RLlibæˆ˜æœ¯æ™ºèƒ½ä½“

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### 1. ç¯å¢ƒæ¿€æ´»
```bash
conda activate dfjsp2t
```

### 2. è¿è¡Œè®­ç»ƒï¼ˆæ¨èï¼‰
```bash
# å®Œæ•´è®­ç»ƒï¼ˆ50æ¬¡è¿­ä»£ï¼Œçº¦3-4åˆ†é’Ÿï¼‰
python hierarchical_train_complete.py

# æˆ–å¿«é€Ÿæµ‹è¯•ï¼ˆ2æ¬¡è¿­ä»£ï¼Œçº¦10ç§’ï¼‰
python quick_test_hierarchical.py
```

### 3. åˆ†æç»“æœ
```bash
python analyze_hierarchical_training.py
```

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œå®Œæ•´çš„è®­ç»ƒæŠ¥å‘Šã€‚

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### â­ å¿…é¡»äº†è§£çš„æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” | ä½•æ—¶ä½¿ç”¨ |
|------|------|----------|
| `hierarchical_train_complete.py` | **ä¸»è®­ç»ƒè„šæœ¬** | ç”Ÿäº§è®­ç»ƒ |
| `analyze_hierarchical_training.py` | ç»“æœåˆ†æ | è®­ç»ƒååˆ†æ |
| `TRAINING_INSTRUCTIONS.md` | è¯¦ç»†ä½¿ç”¨æŒ‡å— | éœ€è¦äº†è§£ç»†èŠ‚æ—¶ |
| `DFJSPT/strategy_controller.py` | ç­–ç•¥å…ƒæ§åˆ¶å™¨ | ç†è§£æ ¸å¿ƒç®—æ³• |
| `DFJSPT/dfjspt_env.py` | ç¯å¢ƒå®šä¹‰ | ç†è§£é—®é¢˜å»ºæ¨¡ |

### âœ… å¯é€‰æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” | ä½•æ—¶ä½¿ç”¨ |
|------|------|----------|
| `quick_test_hierarchical.py` | å¿«é€Ÿæµ‹è¯• | éªŒè¯ç¯å¢ƒé…ç½® |
| `test_strategy_controller.py` | å•å…ƒæµ‹è¯• | å¼€å‘è°ƒè¯• |
| `TRAINING_REPORT.md` | è®­ç»ƒæŠ¥å‘Š | æŸ¥çœ‹å†å²ç»“æœ |
| `visualize_training.py` | å¯è§†åŒ–å·¥å…· | è‡ªå®šä¹‰åˆ†æ |

### ğŸ“ å‚è€ƒæ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” | è¯´æ˜ |
|------|------|------|
| `DFJSPT/dfjspt_train.py` | åŸå§‹è®­ç»ƒè„šæœ¬ | å‘åå…¼å®¹ï¼Œä¸æ¨èä½¿ç”¨ |
| `DFJSPT/hierarchical_env.py` | 4-agentåŒ…è£…å™¨ | å·²åºŸå¼ƒï¼Œä¿ç•™ä½œå‚è€ƒ |

## ğŸ® ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå®Œæ•´è®­ç»ƒè¿è¡Œ
```bash
conda activate dfjsp2t
python hierarchical_train_complete.py
```

**é¢„æœŸç»“æœ**ï¼š
- è®­ç»ƒ50æ¬¡è¿­ä»£
- è€—æ—¶çº¦3-4åˆ†é’Ÿ
- ç”Ÿæˆæ£€æŸ¥ç‚¹åœ¨ `DFJSPT/training_results/hierarchical_v3_YYYYMMDD_HHMMSS/`

### åœºæ™¯2ï¼šè°ƒæ•´è®­ç»ƒå‚æ•°
ç¼–è¾‘ `hierarchical_train_complete.py`ï¼š
```python
# ç¬¬36-38è¡Œ
NUM_ITERATIONS = 100          # æ”¹ä¸º100æ¬¡è¿­ä»£
CHECKPOINT_INTERVAL = 20      # æ¯20æ¬¡ä¿å­˜æ£€æŸ¥ç‚¹
STRATEGY_UPDATE_FREQUENCY = 10  # æ¯10ä¸ªepisodeæ›´æ–°åå¥½
```

### åœºæ™¯3ï¼šå¿«é€ŸéªŒè¯
```bash
python quick_test_hierarchical.py
```
**ç”¨é€”**ï¼šéªŒè¯ç¯å¢ƒé…ç½®æ˜¯å¦æ­£ç¡®

### åœºæ™¯4ï¼šåˆ†æè®­ç»ƒç»“æœ
```bash
python analyze_hierarchical_training.py
```
**ç”Ÿæˆ**ï¼š
- `training_analysis.png` - å¯è§†åŒ–å›¾è¡¨
- æ§åˆ¶å°æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯

### åœºæ™¯5ï¼šä¿®æ”¹é—®é¢˜è§„æ¨¡
ç¼–è¾‘ `DFJSPT/dfjspt_params.py`ï¼š
```python
n_jobs = 20        # æ”¹ä¸º20ä¸ªä½œä¸š
n_machines = 10    # æ”¹ä¸º10å°æœºå™¨
n_transbots = 5    # æ”¹ä¸º5ä¸ªè¿è¾“æœºå™¨äºº
```

## ğŸ”§ é…ç½®æ–‡ä»¶è¯´æ˜

### ä¸»é…ç½®æ–‡ä»¶ï¼š`DFJSPT/dfjspt_params.py`

**å…³é”®å‚æ•°**ï¼š
```python
# é—®é¢˜è§„æ¨¡
n_jobs = 10
n_machines = 5
n_transbots = 3

# å±‚çº§æ¡†æ¶å¼€å…³
use_hierarchical_framework = True  # å¯ç”¨Method 3

# å¤šç›®æ ‡å¥–åŠ±
use_multi_objective_reward = True

# è®­ç»ƒåœæ­¢æ¡ä»¶
stop_iters = 500  # dfjspt_train.pyä½¿ç”¨ï¼ˆä¸æ¨èï¼‰

# å·¥ä½œè¿›ç¨‹
num_workers = 1
num_envs_per_worker = 1
```

### è®­ç»ƒè„šæœ¬å‚æ•°ï¼š`hierarchical_train_complete.py`

**å¯è°ƒæ•´å‚æ•°**ï¼ˆç¬¬36-42è¡Œï¼‰ï¼š
```python
NUM_ITERATIONS = 50              # æ€»è¿­ä»£æ¬¡æ•°
CHECKPOINT_INTERVAL = 10         # æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”
STRATEGY_UPDATE_FREQUENCY = 5    # ç­–ç•¥æ›´æ–°é¢‘ç‡ï¼ˆepisodeï¼‰
EXPLORATION_EPSILON_START = 0.3  # åˆå§‹æ¢ç´¢ç‡
EXPLORATION_EPSILON_END = 0.05   # æœ€ç»ˆæ¢ç´¢ç‡
EXPLORATION_DECAY = 0.95         # æ¢ç´¢è¡°å‡ç‡
```

**RLlibå‚æ•°**ï¼ˆç¬¬78-87è¡Œï¼‰ï¼š
```python
train_batch_size = 2000          # è®­ç»ƒæ‰¹æ¬¡å¤§å°
sgd_minibatch_size = 256         # SGDå°æ‰¹æ¬¡
num_sgd_iter = 10                # SGDè¿­ä»£æ¬¡æ•°
lr = 3e-4                        # å­¦ä¹ ç‡
entropy_coeff = 0.001            # ç†µç³»æ•°
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

### è®­ç»ƒç»“æœç›®å½•ç»“æ„
```
DFJSPT/training_results/hierarchical_v3_YYYYMMDD_HHMMSS/
â”œâ”€â”€ checkpoint_10/
â”‚   â”œâ”€â”€ algorithm_state.pkl      # RLlibæ™ºèƒ½ä½“çŠ¶æ€
â”‚   â”œâ”€â”€ policies/                # ç­–ç•¥ç½‘ç»œå‚æ•°
â”‚   â”œâ”€â”€ strategy_controller.pt   # ç­–ç•¥æ§åˆ¶å™¨
â”‚   â””â”€â”€ training_history.json    # å‰10æ¬¡è¿­ä»£å†å²
â”œâ”€â”€ checkpoint_20/
â”œâ”€â”€ ...
â”œâ”€â”€ final_checkpoint/            # æœ€ç»ˆæ£€æŸ¥ç‚¹
â””â”€â”€ complete_training_history.json  # å®Œæ•´è®­ç»ƒå†å²
```

### è®­ç»ƒå†å²JSONæ ¼å¼
```json
[
  {
    "iteration": 1,
    "preference": [0.287, 0.365, 0.348],  // [æ•ˆç‡, æˆæœ¬, äº¤è´§]
    "reward": -10.388,
    "episodes": 13,
    "timesteps": 2000,
    "exploration_epsilon": 0.3
  },
  ...
]
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œå•å…ƒæµ‹è¯•
```bash
python test_strategy_controller.py
```
**é¢„æœŸè¾“å‡º**ï¼š9ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ âœ…

### å¿«é€Ÿé›†æˆæµ‹è¯•
```bash
python quick_test_hierarchical.py
```
**é¢„æœŸè¾“å‡º**ï¼š2æ¬¡è¿­ä»£æˆåŠŸå®Œæˆï¼Œæ— é”™è¯¯

### æ£€æŸ¥ç¯å¢ƒ
```python
from DFJSPT.dfjspt_env import DfjsptMaEnv

env = DfjsptMaEnv({"train_or_eval_or_test": "train"})
obs, info = env.reset()
print("Environment OK!")
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### å·²éªŒè¯çš„è®­ç»ƒç»“æœï¼ˆ10JÃ—5MÃ—3Tï¼‰

| æŒ‡æ ‡ | åˆå§‹å€¼ | æœ€ç»ˆå€¼ | æ”¹è¿› |
|------|--------|--------|------|
| Episode Reward | -10.39 | -9.92 | +4.5% |
| è®­ç»ƒæ—¶é—´ | - | 3.6åˆ†é’Ÿ | 50æ¬¡è¿­ä»£ |
| æœ€ä½³å¥–åŠ± | - | -9.68 | ç¬¬47æ¬¡è¿­ä»£ |

### ç­–ç•¥å­¦ä¹ ç»“æœ
- **æ”¶æ•›åå¥½**ï¼šæˆæœ¬(41.8%) > æ•ˆç‡(34.8%) > äº¤è´§(23.3%)
- **æ¢ç´¢â†’åˆ©ç”¨**ï¼šåå¥½å˜åŒ–ä»0.11é™è‡³0.006
- **ç­–ç•¥ç¨³å®š**ï¼šå20æ¬¡è¿­ä»£ä¿æŒä¸€è‡´

## âš ï¸ å¸¸è§é—®é¢˜

### Q: è®­ç»ƒæ—¶æŠ¥"single trajectory"é”™è¯¯ï¼Ÿ
**A**: ç¡®ä¿ä½¿ç”¨ `hierarchical_train_complete.py`ï¼Œä¸è¦ä½¿ç”¨ `dfjspt_train.py`

### Q: Rayåˆå§‹åŒ–å¾ˆæ…¢ï¼Ÿ
**A**: æ­£å¸¸ç°è±¡ï¼Œé¦–æ¬¡åˆå§‹åŒ–éœ€è¦10-30ç§’

### Q: å¦‚ä½•åŠ è½½æ£€æŸ¥ç‚¹ï¼Ÿ
**A**: 
```python
from ray.rllib.algorithms.ppo import PPO
algo = PPO.from_checkpoint("path/to/checkpoint_dir")

from DFJSPT.strategy_controller import StrategyController
strategy = StrategyController.load("path/to/strategy_controller.pt")
```

### Q: å†…å­˜ä¸è¶³ï¼Ÿ
**A**: å‡å°‘ `num_workers` æˆ– `train_batch_size`

### Q: æƒ³è¦æ›´å¿«çš„è®­ç»ƒï¼Ÿ
**A**: å¢åŠ  `num_workers`ï¼ˆéœ€è¦æ›´å¤šCPUæ ¸å¿ƒï¼‰

## ğŸ”„ å·¥ä½œæµç¨‹å›¾

```
å¼€å§‹
  â†“
conda activate dfjsp2t
  â†“
python hierarchical_train_complete.py
  â†“
ç­‰å¾…è®­ç»ƒå®Œæˆï¼ˆ3-4åˆ†é’Ÿï¼‰
  â†“
python analyze_hierarchical_training.py
  â†“
æŸ¥çœ‹ training_analysis.png
  â†“
è¯»å– TRAINING_REPORT.md
  â†“
æ ¹æ®éœ€è¦è°ƒæ•´å‚æ•°
  â†“
é‡æ–°è®­ç»ƒæˆ–è¿›è¡Œå…¶ä»–å®éªŒ
```

## ğŸ“š è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰ç­–ç•¥ç½‘ç»œ
ç¼–è¾‘ `DFJSPT/strategy_controller.py` ä¸­çš„ `StrategyNetwork`ï¼š
```python
class StrategyNetwork(nn.Module):
    def __init__(self, obs_dim, action_dim, hidden_dim=128):
        super().__init__()
        # ä¿®æ”¹ç½‘ç»œç»“æ„
        self.net = nn.Sequential(
            nn.Linear(obs_dim, hidden_dim*2),  # å¢åŠ å®¹é‡
            nn.ReLU(),
            nn.Linear(hidden_dim*2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, action_dim)
        )
```

### æ·»åŠ æ–°çš„å¤šç›®æ ‡ç»´åº¦
1. ä¿®æ”¹ `DFJSPT/dfjspt_env.py` çš„ `calculate_multi_objective_reward()`
2. æ›´æ–°ç­–ç•¥ç½‘ç»œçš„ `action_dim`
3. è°ƒæ•´ `EpisodeContextBuilder` çš„è§‚å¯Ÿç»´åº¦

### å®ç°è‡ªå®šä¹‰å›è°ƒ
åœ¨ `hierarchical_train_complete.py` ä¸­æ·»åŠ ï¼š
```python
class CustomCallback(DefaultCallbacks):
    def on_episode_end(self, *, worker, base_env, policies, episode, **kwargs):
        # è‡ªå®šä¹‰é€»è¾‘
        pass

config.callbacks(CustomCallback)
```

## ğŸ“ æ”¯æŒä¸æ–‡æ¡£

- **è¯¦ç»†æŒ‡å—**ï¼š`TRAINING_INSTRUCTIONS.md`
- **è®­ç»ƒæŠ¥å‘Š**ï¼š`TRAINING_REPORT.md`
- **æ¸…ç†æ€»ç»“**ï¼š`FILE_CLEANUP_SUMMARY.md`
- **åŸé¡¹ç›®æ–‡æ¡£**ï¼š`README.md`, `subject.md`

## âœ… æ£€æŸ¥æ¸…å•

å¼€å§‹è®­ç»ƒå‰è¯·ç¡®è®¤ï¼š
- [ ] Condaç¯å¢ƒå·²æ¿€æ´» (`conda activate dfjsp2t`)
- [ ] å‚æ•°å·²é…ç½® (`DFJSPT/dfjspt_params.py`)
- [ ] ä½¿ç”¨æ­£ç¡®çš„è„šæœ¬ (`hierarchical_train_complete.py`)
- [ ] æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆæ¯ä¸ªæ£€æŸ¥ç‚¹çº¦100MBï¼‰
- [ ] æœ‰è¶³å¤Ÿçš„æ—¶é—´ï¼ˆ50æ¬¡è¿­ä»£çº¦4åˆ†é’Ÿï¼‰

è®­ç»ƒåè¯·æ£€æŸ¥ï¼š
- [ ] æ— é”™è¯¯ä¿¡æ¯
- [ ] æ£€æŸ¥ç‚¹å·²ä¿å­˜
- [ ] `complete_training_history.json` å­˜åœ¨
- [ ] è¿è¡Œäº†åˆ†æè„šæœ¬
- [ ] æŸ¥çœ‹äº†å¯è§†åŒ–ç»“æœ

## ğŸ‰ æ€»ç»“

æ‚¨ç°åœ¨æ‹¥æœ‰ä¸€ä¸ª**å®Œæ•´ã€å¯é ã€ç»è¿‡éªŒè¯çš„å±‚çº§å¼ºåŒ–å­¦ä¹ è®­ç»ƒç³»ç»Ÿ**ï¼

- âœ… æ ¸å¿ƒå®ç°ï¼šMethod 3 ç­–ç•¥å…ƒæ§åˆ¶å™¨
- âœ… å®Œæ•´éªŒè¯ï¼š50æ¬¡è¿­ä»£æ— é”™è¯¯
- âœ… ç”Ÿäº§å°±ç»ªï¼šæ£€æŸ¥ç‚¹ã€å†å²ã€åˆ†æå…¨å¥—å·¥å…·
- âœ… æ–‡æ¡£é½å…¨ï¼šä½¿ç”¨æŒ‡å—ã€æŠ¥å‘Šã€APIè¯´æ˜

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€
